The computational efficiency of each algorithm concerns both the
memory used by the algorithm and the number of computational steps
required for the algorithm to execute, which is a measure of the
speed. To characterize the operational efficiency of a digital fractor
operating as a circuit element in real time, the quantities of
interest are the memory or number of processor steps {\em per time
  step}.

There are three phases of the computation that factor into the
computational cost of the binned Gr{\"u}nwald algorithm: initialization
(including summing the binned Gr{\"u}nwald weights), updating the average
values of the stored history in the bins as new input data is read,
and summing the modified Gr{\"u}nwald differ-integral.

During initialization, several things must happen. The array defining
the binning structure, $b_k$, must be set. The history of the input
signal must be zeroed and the first output must be set to zero. Most significantly, the binned weights must be calculated for
the chosen binning structure.

The time it takes to calculate or set $b_k$ is moderately dependent
upon the details of the binning structure chosen. However, any binning
structure will have a processing time that scales as $N_b$, the number of memory storage bins, rather than
$N_h$, the history capacity, because $N_b$ is the number of bins that must be set.

On the other hand, since each of the $N_h$ individual Gr{\"u}nwald weights
must be summed, the time for initialization of the weights scales as
$N_h$. Typical values of $N_h$ are of order $1,000$ to $10^6$. Typical
values of $N_b$ are $10$ to $26$. Since $N_h>>N_b$, the bulk of the
initialization process occurs during the computation of the weights
and the rest of the initialization process may be neglected. The time
for initialization as a whole scales as $N_h$.

By the very design of the algorithm, there is no need to store the
full Gr{\"u}nwald weights. The largest arrays that need to be stored are
the binned weights and the bin capacity, each of which has size
$N_b$. As a result, memory scales as $N_b$ rather than
$N_h$. Equation~\ref{eqn:sumWk} gives the algorithm for the calculation
of the bin weights. The following recursion formula for Gr{\"u}nwald
weights can be used to iterate $w_j$ to a new value with each time
step. In the $j$th time step, $w_j$ has the value

\begin{equation}
w_j = \frac{j-1-\alpha}{j}w_{j-1}.
\label{eqn:GrunwaldRecursion}
\end{equation}

In the implementation of an algorithm for initialization of the
weights, individual G{\"u}nwald weights $w_j$ need not be stored in an
array after calculation. These individual weights can be summed
immediately into the corresponding bin weights $W_k$ according to
Equation~\ref{eqn:sumWk}, at which time the value of $w_j$ may be
safely overwritten with $w_{j+1}$ in order to minimize the amount of
memory required such that it may be possible to later migrate the code
to an mcu.

When new input data is read, the time required to update the binned history values scales as at most $N_b$ because there are $N_b$ bins that must be
updated. Equation~\ref{eqn:updating} may be used as the basis for an
algorithm to accomplish this goal. Care must be taken to account for
the filling of the bins until the approximation reaches steady-state.

This time a memory saving  and speed enhancing opportunity is available. Since only one bin
can be filling at a time and the rest must be either full ($c_k=b_k$)
or empty ($c_k=0$), the full array of $N_b$ occupancy numbers $c_k$
need not be stored. Instead, it is sufficient to store the index of
the bin that is filling, $k_{filling}$ and its occupancy,
$c_{filling}$. These unfilled bins with $k>k_{filling}$ and $c_k=0$
are not updated when a new input signal value is read into the
history. With this approach, the algorithm becomes
\begin{equation}
X_k^\prime = \frac{c_{filling}-1}{c_{filling}}X_k + \frac{1}{c_{filling}}X_{k-1}
\label{eqn:shift1}
\end{equation}
for $k<k_{filling}$ and

\begin{equation}
X_k^\prime = \frac{b_k-1}{b_k}X_k + \frac{1}{b_k}X_{k-1}
\label{eqn:shift2}
\end{equation}
for $k=k_{filling}$ with no shift occurring for $k>k_{filling}$ since
there are no elements in those bins. Since no computation occurs for $k>k_{filling}$, the updating algorithm truly scales as $k_{filling}$ per time step, which is at most $N_b$. 
{\bf above modified: scales as $k_{filling}$}

While it is possible to achieve a memory savings by storing only
$c_{filling}$ and $k_{filling}$, in the C++ code reported in this
paper, the full array of $c_{k}$ is stored. This does not impact the
memory scaling of the updating algorithm. Updating the stored bin
history values scales as $N_b$ in memory because the largest arrays
that need to be stored are the binned average values, the bin
capacity, and the bin occupancy, each of size $N_b$.

{\bf paragraph added}
However, we do implement the speed enhancing aspect of the algorithm. In the code reported in this paper, the calculation is truncated at $k_{filling}$ rather than looping over the full $N_b$ bins to obtain the $k_{filling}$ scaling in time. 

The two real-time operation stages, updating and differ-integrating,
together require less than $400$ flops for $26$ bins of
history. For $26$ bins, less than $100$ memory registers are
required. Initialization, on the other hand, is very
resource-consuming. $N_h$ may be larger than a million and still not
fill $26$ bins. Initialization therefore may require more than a
million flops.

The binned Gr{\"u}nwald algorithm may be written in terms of either the
number of elements per bin, $b_k$, or in terms of the maximum time
step $p_k$ included within each bin (see
Equation~\ref{eqn:sumWk}). While we explain our algorithms in terms of
$b_k$ in this paper, the results derived from our C++ code were
obtained using the $p_k$ method.

{\bf INCLUDE ACTUAL TIMING MEASUREMENTS}
